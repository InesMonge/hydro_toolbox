{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-18T14:33:53.974110Z",
     "start_time": "2025-06-18T14:33:53.971531Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from utils.data_reading.sound_data.station import StationsCatalog\n",
    "from scipy import signal\n",
    "from utils.transformation.signal import butter_bandpass_filter\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:23:23.600897Z",
     "start_time": "2025-06-18T14:23:23.564236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "aplose_dir = \"../../../../data/SPL/aplose.csv\"\n",
    "output_path = \"../../../../data/SPL\"\n",
    "catalog_path = \"/media/imonge/CORSAIR\"\n",
    "stations = StationsCatalog(catalog_path)"
   ],
   "id": "748552988a60e74a",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:23:24.737872Z",
     "start_time": "2025-06-18T14:23:24.692114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Change csv in pkl format\n",
    "df = pd.read_csv(aplose_dir, parse_dates=[\"start_datetime\", \"end_datetime\"])\n",
    "df.to_pickle(os.path.join(output_path,'aplose.pkl'))\n",
    "df = pd.read_pickle('../../../../data/SPL/aplose.pkl')"
   ],
   "id": "9c12ac39c327c0d6",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:23:25.578698Z",
     "start_time": "2025-06-18T14:23:25.571822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Rename labels\n",
    "labels_info = {\n",
    "    # Whales\n",
    "    \"Dcall\": ('BW_dcall', 'Blue Whale D-call'),\n",
    "    \"Antarctic blue whale song\": ('ABW', 'Antarctic blue whale'),\n",
    "    \"Australian pygmy blue whale song\": ('PBW_SEIO', 'Australian pygmy blue whale'),\n",
    "    \"Madagascan pygmy blue whale song\": ('PBW_SWIO', 'Madagascan pygmy blue whale'),\n",
    "    \"Sri Lanka pygmy blue whale song\": ('PBW_CIO', 'Sri Lankan pygmy blue whale'),\n",
    "    \"Omura Australia (19-25 Hz)\": ('Omura_SEIO', \"Australian Omura's whale\"),\n",
    "    \"Omura DGC LF (20 Hz)\": ('Omura_SWIO', \"Madagascan Omura's whale\"),\n",
    "    \"Omura DGC HF (30-40Hz)\": ('Omura_CIO', \"Diego Garcian Omura's whale\"),\n",
    "    \"Minke whale\": ('Minke', 'Minke whale'),\n",
    "    \"Fin whale 40 Hz\": ('FW_nsp', 'Fin whale non stereotyped pulse'),\n",
    "    \"Fin whale 20 Hz\": ('FW_20Hz', 'Fin whale 20-Hz pulse'),\n",
    "    # Whales ind\n",
    "    \"P-call\": ('P_call', 'P-call'),\n",
    "    \"Ind 42 Hz\": ('ind_42Hz', 'Indeterminate species - 42 Hz'),\n",
    "    \"LF 8 sec pulse\": ('ind_8s', 'Indeterminate species -  8 sec'),\n",
    "\n",
    "    # Geophony\n",
    "    \"T-wave\": ('eq', 'earthquake'),\n",
    "    \"impulse_geo\": ('impuls_geo', 'Impulsive volcanic event'),\n",
    "\n",
    "    # Anthropophony\n",
    "    \"career_shot\": ('career_shot', 'Career shot'),\n",
    "    \"Airgun\": ('seismic_shot', 'Seismic shot'),\n",
    "    \"ship_noise\": ('ship_noise', 'Ship noise'),\n",
    "    \"anthropophony\": ('ind_anthro', 'Indeterminate anthropophony')\n",
    "}\n",
    "\n",
    "# retrieve \"short name\"\n",
    "short_name = {k: v[0] for k, v in labels_info.items()}\n",
    "\n",
    "# Change label names\n",
    "df['annotation'] = df['annotation'].replace(short_name)\n",
    "\n",
    "# # Retrieve \"long name\"\n",
    "# long_name = {v[0]: v[1] for v in labels_info.items()}\n",
    "# df['long_name'] = df['annotation'].map(long_name)"
   ],
   "id": "218a42d018771778",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:23:26.248335Z",
     "start_time": "2025-06-18T14:23:26.243957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove \"weak\" lines (except for ship_noise)\n",
    "df = df[~((df['type'] == 'weak') & (df['annotation'] != 'ship_noise'))]"
   ],
   "id": "22d4af246bb1c280",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:23:27.167355Z",
     "start_time": "2025-06-18T14:23:27.163988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove lines with only a comment\n",
    "df = df[df['annotation'].notna()]"
   ],
   "id": "1ab67c7c6dfb0ac8",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:23:28.095968Z",
     "start_time": "2025-06-18T14:23:28.092337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove umpty columns\n",
    "columns_to_delete = ['signal_quality', 'signal_start_frequency', 'signal_end_frequency', 'signal_relative_max_frequency_count', 'signal_relative_min_frequency_count', 'signal_has_harmonics', 'signal_trend', 'signal_steps_count', 'annotator_expertise']\n",
    "df = df.drop(columns=columns_to_delete)"
   ],
   "id": "4482786712e4a891",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:23:30.199422Z",
     "start_time": "2025-06-18T14:23:30.196974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example_line = df.iloc[0]\n",
    "possible_stations = stations.by_date(example_line[\"start_datetime\"].tz_localize(None))  # [MAHY11, MAHY13, MAHY14]\n",
    "station_number = example_line[\"filename\"].split(\"_\")[1][-1]  # \"1\"\n",
    "station_number_to_station = {s.name[-1]:s for s in possible_stations}  # {'1':MAHY11, '3':MAHY13, '4':MAHY14}\n",
    "station = station_number_to_station[station_number]  # MAHY11"
   ],
   "id": "38319aa71441085",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T14:40:29.713208Z",
     "start_time": "2025-06-18T14:38:57.396467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "psds = []\n",
    "index = []\n",
    "nperseg = 512\n",
    "nperseg_sec = 515/240\n",
    "\n",
    "# Retrieve station name from the available data in the aplose dataset\n",
    "for i in tqdm(df.index):\n",
    "    line = df.iloc[i]\n",
    "    possible_stations = stations.by_date(line[\"start_datetime\"].tz_localize(None))  # [MAHY11, MAHY13, MAHY14]\n",
    "    station_number = line[\"filename\"].split(\"_\")[1][-1]  # \"1\"\n",
    "    station_number_to_station = {s.name[-1]:s for s in possible_stations}  # {'1':MAHY11, '3':MAHY13, '4':MAHY14}\n",
    "    station = station_number_to_station[station_number]  # MAHY11\n",
    "\n",
    "    # Compute PSDs on the annotation boxes\n",
    "    manager = station.get_manager()\n",
    "\n",
    "    date_start = line['start_datetime'].tz_localize(None)\n",
    "    date_end = line['end_datetime'].tz_localize(None)\n",
    "    delta = (date_end - date_start).total_seconds()\n",
    "\n",
    "    # Widen boxes which areto short\n",
    "    if delta < nperseg_sec:\n",
    "        diff = nperseg_sec - delta\n",
    "        date_end = date_end + datetime.timedelta(seconds=diff)\n",
    "\n",
    "    # Frequency range when we have weak annotations ('ship_noise')\n",
    "    if line['is_box'] == 0:\n",
    "        start_frequency = 1e-3 # does not tolerate strict 0 Hz\n",
    "        end_frequency=120 - 1e-3 # does not tolerate strict 120 Hz\n",
    "    else:\n",
    "        start_frequency = line['start_frequency'] + 1e-3\n",
    "        end_frequency = line['end_frequency'] - 1e-3\n",
    "\n",
    "    data = manager.get_segment(date_start, date_end)\n",
    "    data = butter_bandpass_filter(data, start_frequency, end_frequency, manager.sampling_f)  # on filtre entre 40 et 45 Hz, en spécifiant la fréquence d'échantillonage (on pourrait mettre 240 \"en dur\" aussi)\n",
    "\n",
    "    psd_frequencies, psd = signal.welch(data, fs=240, nperseg=nperseg) # methode pour avoir les pics spl\n",
    "    psds.append(psd)\n",
    "    index.append(i)\n",
    "\n",
    "# Save computed psds in a dataframe\n",
    "df_psd = pd.DataFrame(psds, index=index, columns=psd_frequencies)\n",
    "df_psd.to_pickle(os.path.join(output_path, 'psd_aplose.pkl'))\n",
    "\n",
    "# Si on prend moyenne -> rms\n",
    "# si on prend max -> peak frequency"
   ],
   "id": "9a9e474ccb106fa7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/6063 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "80c32d62c9494d4489febb13571c8092"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Add columns for the peak frequency\n",
    "## Ongoing work ##"
   ],
   "id": "4152c55e30b3a9b6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
